{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /></center>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Advanced Data Augmentation with Keras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimated time needed:  30 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn to implement and experiment with various data augmentation techniques using Keras in this lab. \n",
    "\n",
    "#### Learning objectives \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement various data augmentation techniques using Keras \n",
    "- Implement feature-wise and sample-wise normalization on the data set. \n",
    "- Define and apply a custom augmentation function that adds random noise to images. \n",
    "- Display the augmented images to understand the effect of different augmentation techniques.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-by-step instructions \n",
    "\n",
    "##### Step 1: Setup the environment \n",
    "\n",
    "First, you need to import the necessary libraries and load the data set as follows: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.16.2\n",
      "  Downloading tensorflow-2.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting matplotlib==3.9.1\n",
      "  Downloading matplotlib-3.9.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.16.2)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.16.2)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.16.2)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.16.2)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.16.2)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.16.2)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.16.2)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2)\n",
      "  Downloading ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.16.2)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.2)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.16.2)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.16.2)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.16.2)\n",
      "  Downloading grpcio-1.74.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow==2.16.2)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow==2.16.2)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.1)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.1)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.1)\n",
      "  Downloading fonttools-4.59.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (109 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.1)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.1)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.1)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.1) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2) (0.45.1)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'matplotlib' candidate (version 3.9.1 at https://files.pythonhosted.org/packages/0d/cb/78283ec2ded91fb74a2ae9ae93f91a897fa578fa78c8c271a7c147f6b8d6/matplotlib-3.9.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/matplotlib/) (requires-python:>=3.9))\n",
      "Reason for being yanked: The Windows wheels, under some conditions, caused segfaults in unrelated user code.  Due to this we deleted the Windows wheels to prevent these segfaults, however this caused greater disruption as pip then began to try (and fail) to build 3.9.1 from the sdist on Windows which impacted far more users.  Yanking the whole release is the only tool available to eliminate these failures without changes to on the user side.  The sdist, OSX wheel, and manylinux wheels are all functional and there are no critical bugs in the release.   Downstream packagers should not yank their builds of Matplotlib 3.9.1.  See https://github.com/matplotlib/matplotlib/issues/28551 for details.\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading tensorflow-2.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.8/590.8 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.9.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading fonttools-4.59.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.74.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, pyparsing, protobuf, pillow, optree, opt-einsum, numpy, mdurl, markdown, kiwisolver, grpcio, google-pasta, gast, fonttools, cycler, astunparse, absl-py, tensorboard, scipy, ml-dtypes, markdown-it-py, h5py, contourpy, rich, matplotlib, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 contourpy-1.3.3 cycler-0.12.1 flatbuffers-25.2.10 fonttools-4.59.2 gast-0.6.0 google-pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 keras-3.11.3 kiwisolver-1.4.9 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 matplotlib-3.9.1 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.1.0 numpy-1.26.4 opt-einsum-3.4.0 optree-0.17.0 pillow-11.3.0 protobuf-4.25.8 pyparsing-3.2.3 rich-14.1.0 scipy-1.16.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 11:56:57.565190: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-06 11:56:57.566474: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-06 11:56:57.571802: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-06 11:56:57.585123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-06 11:56:57.610422: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-06 11:56:57.610464: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-06 11:56:57.626665: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-06 11:56:58.819876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m 94658560/170498071\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0us/step"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install tensorflow==2.16.2 matplotlib==3.9.1 scipy\n",
    "\n",
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load CIFAR-10 dataset for training images\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values for augmentation\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Display a sample of the training images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create sample.jpg for the Lab**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Create a blank white image\n",
    "image = Image.new('RGB', (224, 224), color = (255, 255, 255))\n",
    "\n",
    "# Draw a red square\n",
    "draw = ImageDraw.Draw(image)\n",
    "draw.rectangle([(50, 50), (174, 174)], fill=(255, 0, 0))\n",
    "\n",
    "# Save the image\n",
    "image.save('sample.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array \n",
    "\n",
    "# Load a sample image \n",
    "img_path = 'sample.jpg' \n",
    "img = load_img(img_path) \n",
    "x = img_to_array(img) \n",
    "x = np.expand_dims(x, axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code: \n",
    "- `!pip install tensorflow==2.16.2 matplotlib==3.9.1` installs the specified versions of `TensorFlow and Matplotlib`.  \n",
    "\n",
    "- `tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "- `Model` is used to create a model with the Functional API. \n",
    "\n",
    "- `Input` and ‘Dense’ are types of layers that you will use in your model.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Basic data augmentation \n",
    "\n",
    "Apply basic augmentations such as rotation, width shift, height shift, shear, zoom, and horizontal flip using the ImageDataGenerator as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# Load the sample image\n",
    "img_path = 'sample.jpg'\n",
    "img = load_img(img_path)\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Create an instance of ImageDataGenerator with basic augmentations\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generate batches of augmented images\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(batch[0].astype('uint8'))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 3: Feature-wise and sample-wise normalization \n",
    "\n",
    "Implement feature-wise and sample-wise normalization on the data set as follows:    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ImageDataGenerator with normalization options\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True\n",
    ")\n",
    "\n",
    "# Load the sample image again and fit the generator (normally done on the training set)\n",
    "datagen.fit(x)\n",
    "\n",
    "# Generate batches of normalized images\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(batch[0].astype('uint8'))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Step 4: Custom data augmentation function \n",
    "\n",
    "Next, you define and apply a custom augmentation function that adds random noise to images as follows: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom data augmentation function\n",
    "def add_random_noise(image):\n",
    "    noise = np.random.normal(0, 0.1, image.shape)\n",
    "    return image + noise\n",
    "\n",
    "# Create an instance of ImageDataGenerator with the custom augmentation\n",
    "datagen = ImageDataGenerator(preprocessing_function=add_random_noise)\n",
    "\n",
    "# Generate batches of augmented images with noise\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(batch[0].astype('uint8'))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Visualize augmented images \n",
    "\n",
    "Visualize the augmented images to understand the impact of each augmentation technique. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing multiple augmented versions of the same image\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, batch in enumerate(datagen.flow(x, batch_size=1)):\n",
    "    if i >= 4:  # Show only 4 versions\n",
    "        break\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(batch[0].astype('uint8'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This Markdown explanation will provide clarity in a Jupyter Notebook, making the code and its purpose easier to understand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Apply and Visualize Different Augmentation Techniques \n",
    "\n",
    "  \n",
    "\n",
    "Objective: Experiment with different augmentation techniques and visualize their effects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `sample_images` folder containing a collection of images that will be used for this practice exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/RgP3JFNtPTZA34UmG3KZaA/sample-images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the images by unzipping the folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip sample-images.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions: \n",
    "\n",
    "1. Create an instance of `ImageDataGenerator` with various augmentations such as rotation, width shift, height shift, shear, zoom, and horizontal flip. \n",
    "\n",
    "2. Generate and visualize augmented images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img  \n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import numpy as np  \n",
    "\n",
    " \n",
    "\n",
    "# Define the augmentation parameters  \n",
    "\n",
    "datagen = ImageDataGenerator(  \n",
    "\n",
    "    rotation_range=40,  \n",
    "\n",
    "    width_shift_range=0.2,  \n",
    "\n",
    "    height_shift_range=0.2,  \n",
    "\n",
    "    shear_range=0.2,  \n",
    "\n",
    "    zoom_range=0.2,  \n",
    "\n",
    "    horizontal_flip=True,  \n",
    "\n",
    "    fill_mode='nearest'  \n",
    "\n",
    ")  \n",
    "\n",
    " \n",
    "\n",
    "# Load and preprocess the dataset  \n",
    "\n",
    "image_paths = [  \n",
    "\n",
    "    'sample_images/training_images1.jpg',  \n",
    "\n",
    "    'sample_images/training_images2.jpg',  \n",
    "\n",
    "    'sample_images/training_images3.jpg'  \n",
    "\n",
    "]  \n",
    "\n",
    " \n",
    "\n",
    "training_images = []  \n",
    "\n",
    "for image_path in image_paths:  \n",
    "\n",
    "    img = load_img(image_path, target_size=(224, 224))  \n",
    "\n",
    "    img_array = img_to_array(img)  \n",
    "\n",
    "    training_images.append(img_array)  \n",
    "\n",
    "training_images = np.array(training_images)  \n",
    "\n",
    " \n",
    "\n",
    "# Generate and visualize augmented images  \n",
    "\n",
    "i = 0  \n",
    "\n",
    "for batch in datagen.flow(training_images, batch_size=1):  \n",
    "\n",
    "    plt.figure(i)  \n",
    "\n",
    "    imgplot = plt.imshow(array_to_img(batch[0]))  \n",
    "\n",
    "    plt.title(f'Augmented Image {i + 1}')  \n",
    "\n",
    "    i += 1  \n",
    "\n",
    "    if i % 4 == 0:  \n",
    "\n",
    "        break  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    " \n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img  \n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import numpy as np  \n",
    "\n",
    " \n",
    "\n",
    "# Define the augmentation parameters  \n",
    "\n",
    "datagen = ImageDataGenerator(  \n",
    "\n",
    "    rotation_range=40,  \n",
    "\n",
    "    width_shift_range=0.2,  \n",
    "\n",
    "    height_shift_range=0.2,  \n",
    "\n",
    "    shear_range=0.2,  \n",
    "\n",
    "    zoom_range=0.2,  \n",
    "\n",
    "    horizontal_flip=True,  \n",
    "\n",
    "    fill_mode='nearest'  \n",
    "\n",
    ")  \n",
    "\n",
    " \n",
    "\n",
    "# Load and preprocess the dataset  \n",
    "\n",
    "image_paths = [  \n",
    "\n",
    "    'sample_images/training_images1.jpg',  \n",
    "\n",
    "    'sample_images/training_images2.jpg',  \n",
    "\n",
    "    'sample_images/training_images3.jpg'  \n",
    "\n",
    "]  \n",
    "\n",
    " \n",
    "\n",
    "training_images = []  \n",
    "\n",
    "for image_path in image_paths:  \n",
    "\n",
    "    img = load_img(image_path, target_size=(224, 224))  \n",
    "\n",
    "    img_array = img_to_array(img)  \n",
    "\n",
    "    training_images.append(img_array)  \n",
    "\n",
    "training_images = np.array(training_images)  \n",
    "\n",
    " \n",
    "\n",
    "# Generate and visualize augmented images  \n",
    "\n",
    "i = 0  \n",
    "\n",
    "for batch in datagen.flow(training_images, batch_size=1):  \n",
    "\n",
    "    plt.figure(i)  \n",
    "\n",
    "    imgplot = plt.imshow(array_to_img(batch[0]))  \n",
    "\n",
    "    plt.title(f'Augmented Image {i + 1}')  \n",
    "\n",
    "    i += 1  \n",
    "\n",
    "    if i % 4 == 0:  \n",
    "\n",
    "        break  \n",
    "\n",
    "plt.show()  \n",
    "\n",
    " ```   \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Feature-wise and Sample-wise Normalization\n",
    " \n",
    "Objective: Apply feature-wise and sample-wise normalization to the dataset.\n",
    " \n",
    "Instructions:\n",
    "1. Create an instance of `ImageDataGenerator` with feature-wise and sample-wise normalization.\n",
    "2. Fit the `ImageDataGenerator` to the data set and visualize the normalized images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    " \n",
    "\n",
    "# Create an instance of ImageDataGenerator with normalization options  \n",
    "\n",
    "datagen = ImageDataGenerator(  \n",
    "\n",
    "    featurewise_center=True,  \n",
    "\n",
    "    featurewise_std_normalization=True,  \n",
    "\n",
    "    samplewise_center=True,  \n",
    "\n",
    "    samplewise_std_normalization=True  \n",
    "\n",
    ")  \n",
    "\n",
    " \n",
    "\n",
    "# Fit the ImageDataGenerator to the dataset  \n",
    "\n",
    "datagen.fit(training_images)  \n",
    "\n",
    " \n",
    "\n",
    "# Generate and visualize normalized images  \n",
    "\n",
    "i = 0  \n",
    "\n",
    "for batch in datagen.flow(training_images, batch_size=1):  \n",
    "\n",
    "    plt.figure(i)  \n",
    "\n",
    "    imgplot = plt.imshow(array_to_img(batch[0]))  \n",
    "\n",
    "    plt.title(f'Normalized Image {i + 1}')  \n",
    "\n",
    "    i += 1  \n",
    "\n",
    "    if i % 4 == 0:  \n",
    "\n",
    "        break  \n",
    "\n",
    "plt.show()  \n",
    "\n",
    " \n",
    "\n",
    " ```   \n",
    "\n",
    "</details>\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Create and Apply a Custom Data Augmentation Function\n",
    " \n",
    "Objective: Define a custom data augmentation function that adds random noise to images and apply it.\n",
    " \n",
    "Instructions:\n",
    "1. Define a function that adds random noise to an image.\n",
    "2. Create an instance of `ImageDataGenerator` with the custom augmentation function.\n",
    "3. Generate and visualize augmented images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    " \n",
    "\n",
    "# Define a custom augmentation function to add random noise  \n",
    "\n",
    "def add_random_noise(image):  \n",
    "\n",
    "    noise = np.random.normal(0, 0.1, image.shape)  \n",
    "\n",
    "    return image + noise  \n",
    "\n",
    " \n",
    "\n",
    "# Create an instance of ImageDataGenerator with custom augmentation  \n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=add_random_noise)  \n",
    "\n",
    " \n",
    "\n",
    "# Generate and visualize augmented images  \n",
    "\n",
    "i = 0  \n",
    "\n",
    "for batch in datagen.flow(training_images, batch_size=1):  \n",
    "\n",
    "    plt.figure(i)  \n",
    "\n",
    "    imgplot = plt.imshow(array_to_img(batch[0]))  \n",
    "\n",
    "    plt.title(f'Noisy Image {i + 1}')  \n",
    "\n",
    "    i += 1  \n",
    "\n",
    "    if i % 4 == 0:  \n",
    "\n",
    "        break  \n",
    "\n",
    "plt.show()  \n",
    "\n",
    " ```   \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "Congratulations! You have successfully implemented and experimented with various data augmentation techniques using Keras. This lab exercise demonstrated how to use Keras to enhance your datasets through augmentation and normalization techniques. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skillup \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "457a8ca8852b9f780653ab511cbd19afe6777bafc1774c1f5e8186ccf67f3998"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
